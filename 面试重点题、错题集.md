# 面试重点题、错题集

⚠本错题集回答为个人见解仅供参考



+ epoll 过程

> epoll使用epoll_create()在内核创建epoll对象，内核中使用红黑树来跟踪所有待检测文件描述符。把监控的socket通过epoll_ctl()加入到内核红黑树，不用每次传一个集合，只传入一个待检测socket。
> 内核中epoll使用事件驱动系统，维护一个链表记录就绪事件。当某socket有事件时通过回调函数将其加入就绪事件链表，当某用户调用epoll_wait()，只返回有网络事件的socket的个数，而不是轮询扫描fd集合

+ LT和ET触发模式

> 水平触发（LT，Level Trigger）模式下，只要一个文件描述符就绪，就会触发通知，如果用户程序没有一次性把数据读写完，下次还会通知；
> 边缘触发（ET，Edge Trigger）模式下，当描述符从未就绪变为就绪时通知一次，之后不会再通知，直到再次从未就绪变为就绪（缓冲区从不可读/写变为可读/写）。
> 区别：边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。
> 为什么边缘触发一定要用非阻塞（non-block）IO：避免由于一个描述符的阻塞读/阻塞写操作让处理其它描述符的任务出现饥饿状态。

+ MySQL了解过吗？ 讲一下索引的底层

> 索引底层用b+树实现，MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。
> InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。
>
> 第一个重大区别是InnoDB的数据文件本身就是索引文件。MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。

+ b+树 时间复杂度

> 层数log(m)n，每一层平均m/2（每一层平均都要遍历m/2个节点才能确定往下面哪一个分支走），所以一共是(m/2) * log(m)n，由于m是常数，所以复杂度O(log n)，即以2为底n的对数。

+ 哈希索引和b+树索引的区别

> 哈希索引能以 O(1) 时间进行查找，但是只支持精确查找，无法用于部分查找和范围查找，无法用于排序与分组；B树索引支持大于小于等于查找，范围查找。哈希索引遇到大量哈希值相等的情况后查找效率会降低。哈希索引不支持数据的排序

+ shared_ptr缺点

> 智能指针可能出现的问题：循环引用，在两个类中分别定义另一个类的对象的共享指针，由于在程序结束后，两个指针相互指向对方的内存空间，导致内存无法释放。

+ string底层分配空间

> 第一次申请的时候就申请一块大一些的内存，比如初始化的字符串长度为10，就申请一块大小为20的内存，如果这块内存用完了而字符串还需要扩展，那就去找一块更大的内存，能够同时容纳需要的内存空间，而且还有一些余量，直接将字符串整体迁移到新内存空间中，放弃原来那部分内存空间，这样就实现了字符串的内存连续。

+ SSL握手流程

> 客户端向服务器发送请求，同时发送客户端支持的一套加密规则（包括对称加密、非对称加密、摘要算法）；
> 服务器从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥（用于非对称加密），以及证书的颁发机构等信息（证书中的私钥只能用于服务器端进行解密）；
> 客户端验证服务器的合法性，包括：证书是否过期，CA（证书颁发机构） 是否可靠，发行者证书的公钥能否正确解开服务器证书的“发行者的数字签名”，服务器证书上的域名是否和服务器的实际域名相匹配；
> 如果证书受信任，或者用户接收了不受信任的证书，浏览器会生成一个随机密钥（用于对称算法），并用服务器提供的公钥加密（采用非对称算法对密钥加密）；使用Hash算法对握手消息进行摘要计算，并对摘要使用之前产生的密钥加密（对称算法）；将加密后的随机密钥和摘要一起发送给服务器；
> 服务器使用自己的私钥解密，得到对称加密的密钥，用这个密钥解密出Hash摘要值，并验证握手消息是否一致；如果一致，服务器使用对称加密的密钥加密握手消息发给浏览器；
> 浏览器解密并验证摘要，若一致，则握手结束。之后的数据传送都使用对称加密的密钥进行加密

+ 利用二分法求一个数的平方根,精度要求 e < 10^-6

> ```cc
> #include <math.h> 
> 
> double sqrt(double x )
> {
>  double low= 0;double up=x;
>  double mid = low + (up - low)/ 2;
>  while (fabs(mid * mid - x) >=1e-6)
>  {
>   mid = low + (up - low) / 2;
>   if (mid * mid > x) up = mid;
>   else if (mid * mid < x) low = mid;
>  }
>  return mid;
> }
> ```

+ 如何只用2GB内存从20/40/80亿个整数中找到出现次数最多的数?

> 可以采用哈希表来统计，把这个数作为 key，把这个数出现的次数作为 value，之后我再遍历哈希表哪个数出现最多的次数。
> key 和 value 都是 int 型整数，一个 int 型占用 4B 的内存，所以哈希表的一条记录需要占用 8B，最坏的情况下，这 20 亿个数都是不同的数，大概会占用 16GB 的内存.
> 可以把这 20 亿个数映射到不同的文件中去，例如，数值在 0 至 2亿之间的存放在文件1中，数值在2亿至4亿之间的存放在文件2中….，由于 int 型整数大概有 42 亿个不同的数，所以我可以把他们映射到 21 个文件中去.

+ 如果我给的这 20 亿个数数值比较集中的话，例如都处于 1~20000000 之间，那么你都会把他们全部映射到同一个文件中，你有优化思路吗？

> 可以先把每个数先做哈希函数映射，根据哈希函数得到的哈希值，再把他们存放到对应的文件中，如果哈希函数设计到好的话，那么这些数就会分布的比较平均。

+ 那如果我把 20 亿个数加到 40 亿个数呢？

> 可以加大文件的数量

+ 如果我给的这 40 亿个数中数值都是一样的，那么你的哈希表中，某个 key 的 value 存放的数值就会是 40 亿，然而 int 的最大数值是 21 亿左右，那么就会出现溢出，你该怎么办？

> 我可以把 value 初始值赋值为 负21亿，这样，如果 value 的数值是 21 亿的话，就代表某个 key 出现了 42 亿次了。

+ 那我如果把 40 亿增加到 80 亿呢？

> 一边遍历一遍判断啊，如果我在统计的过程中，发现某个 key 出现的次数超过了 40 亿次，那么，就不可能再有另外一个 key 出现的次数比它多了，那我直接把这个 key 返回。

+ free和delete的区别

> 1. delete 用于释放 new 分配的空间，free 有用释放 malloc 分配的空间
>
> 2. delete [] 用于释放 new [] 分配的空间
>
> 3. delete 释放空间的时候会调用 相应对象的析构函数
>
>     顺便说一下new在分配空间的时候同时会调用对象的构造函数，对对象进行初始化，使用malloc则只是分配内存
>
> 4. 调用free 之前需要检查 需要释放的指针是否为空，使用delete 释放内存则不需要检查指针是否为NULL
>
> 5. malloc、free 是库函数，而new、delete 是关键字。 new 申请空间时，无需指定分配空间的大小，编译器会根据类型自行计算；malloc 在申请空间时，需要确定所申请空间的大小。

+ GET与POST的区别？

> GET是幂等的，即读取同一个资源，总是得到相同的数据，POST不是幂等的；
>
> 幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同
>
> GET一般用于从服务器获取资源，而POST有可能改变服务器上的资源；
>
> 请求形式上：GET请求的数据附在URL之后，在HTTP请求头中；POST请求的数据在请求体中；
>
> 安全性：GET请求可被缓存、收藏、保留到历史记录，且其请求数据明文出现在URL中。POST的参数不会被保存，安全性相对较高；
>
> GET只允许ASCII字符，POST对数据类型没有要求，也允许二进制数据；
>
> GET的长度有限制（操作系统或者浏览器），而POST数据大小无限制

+ post的数据很大怎么办

> 原则上post是默认无限制的，多大的数据都可以请求，
> 但是springboot内置的tomcat服务器，对这post请求做了默认限制，
> maxPostsize为2m；
>
> Tomcat的配置文件里取消POST大小限制，在conf目录下，server.xml文件，修改：
>
> ```
> <Connector port="8080" protocol="HTTP/1.1"  
>       connectionTimeout="20000"  
>       redirectPort="8443" maxPostSize="0"/>  
> ```
>
> maxPostSize=”0”,即取消POST的大小限制；

+ 如何传输大文件

> 数据压缩
> 浏览器在发送请求时都会带着 Accept-Encoding 头字段，里面是浏览器支持的压缩格式列表，例如 gzip、deflate、br 等，这样服务器就可以从中选择一种压缩算法，放进 Content-Encoding 响应头里，再把原数据压缩后发给浏览器。
>
> 分块传输
> 除了压缩文件之外，另一种办法就是分块传输。它们的原理差不多，都是把大文件变小传输。分块传输会把一个大文件切成很多小块，把这些小块依次发给浏览器，浏览器收到之后再组装复原。这样浏览器和服务器都不用在内存中保存全部文件，每次只收发一小部分，网络也不会被大文件长时间占用，内存、带宽等资源也就节省下来了。
>
> 具体实现是在 response 响应报文里用头字段 Transfer-Encoding: chunked 来表示，表示报文里的 body 部分不是一次性发过来的，而是分成了许多的块（chunk）逐个发送。当 chunk 为 0 时说明是最后一个，传输结束。
>
> 范围请求
> 为什么会有范围请求？
>
> 你看电影时，想跳过开头直接看正片，这实际上是想获取一个大文件其中的片段数据，而分块传输没有这个能力。
>
> HTTP 协议为了满足这种需求，提出了「范围请求」的概念，允许客户端在请求头里使用专用字段来表示只获取文件的一部分。
>
> 范围请求不是 Web 服务器必须实现的功能，所以服务器必须在响应头里使用字段 「Accept-Ranges: bytes 」明确告知客户端自己支持范围请求。如果不支持的话，服务器就会发送「Accept-Ranges：none」或者不发送此字段。这样客户端就只能收发整块文件了。

+ 堆是平衡二叉树吗

> 平衡二叉树（Balanced Binary Tree）又被称为AVL树（有别于AVL算法），且具有以下性质：它是一 棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。这个方案很好的解决了二叉查找树退化成链表的问题，把插入，查找，删除的时间复杂度最好情况和最坏情况都维持在O(logN)
>
> 1 堆是一种完全二叉树（不是平衡二叉树，也不是二分搜索树哦）
> 2 堆要求孩子节点要小于等于父亲节点（如果是最小堆则大于等于其父亲节点）

+ 图的存储结构

> 1. 邻接矩阵
>
>    ![image-20210809233547688](https://gitee.com/ahrunio/pic-go-image-hosting-service/raw/master/img/image-20210809233547688.png)
>
>    2. 邻接表
>
>       ![image-20210809233622872](https://gitee.com/ahrunio/pic-go-image-hosting-service/raw/master/img/image-20210809233622872.png)
>
>       3. 十字链表
>       4. 多重邻接表

+ MySQL 的Join及底层实现原理

> MySQL是只支持一种JOIN算法Nested-Loop Join（嵌套循环链接），不过MySQL的Nested-Loop Join（嵌套循环链接）也是有很多变种，能够帮助MySQL更高效的执行JOIN操作：
>
> （1）Simple Nested-Loop Join
>
> ![image-20210809233857623](https://gitee.com/ahrunio/pic-go-image-hosting-service/raw/master/img/image-20210809233857623.png)
>
> 从驱动表中取出R1匹配S表所有列，然后R2，R3,直到将R表中的所有数据匹配完，然后合并数据，可以看到这种算法要对S表进行RN次访问，虽然简单，但是相对来说开销还是太大了
>
> （2）Index Nested-Loop Join
>
> ![image-20210809234051786](https://gitee.com/ahrunio/pic-go-image-hosting-service/raw/master/img/image-20210809234051786.png)
>
> 索引嵌套联系由于非驱动表上有索引，所以比较的时候不再需要一条条记录进行比较，而可以通过索引来减少比较，从而加速查询。
>
> 这种算法在链接查询的时候，驱动表会根据关联字段的索引进行查找，当在索引上找到了符合的值，再回表进行查询，也就是只有当匹配到索引以后才会进行回表。至于驱动表的选择，MySQL优化器一般情况下是会选择记录数少的作为驱动表，但是当SQL特别复杂的时候不排除会出现错误选择。（ON后面写索引的字段就完事了）
>
> 在索引嵌套链接的方式下，如果非驱动表的关联键是主键的话，这样来说性能就会非常的高，如果不是主键的话，关联起来如果返回的行数很多的话，效率就会特别的低，因为要多次的回表操作。
>
> （3）Block Nested-Loop Join
>
> ![image-20210809234240285](https://gitee.com/ahrunio/pic-go-image-hosting-service/raw/master/img/image-20210809234240285.png)
>
> 在有索引的情况下，MySQL会尝试去使用Index Nested-Loop Join算法，在有些情况下，可能Join的列就是没有索引，那么这时MySQL的选择绝对不会是最先介绍的Simple Nested-Loop Join算法，而是会优先使用Block Nested-Loop Join的算法。
>
> Block Nested-Loop Join对比Simple Nested-Loop Join多了一个中间处理的过程，也就是join buffer，使用join buffer将驱动表的查询JOIN相关列都给缓冲到了JOIN BUFFER当中，然后批量与非驱动表进行比较，这也来实现的话，可以将多次比较合并到一次，降低了非驱动表的访问频率。也就是只需要访问一次S表。这样来说的话，就不会出现多次访问非驱动表的情况了，也只有这种情况下才会访问join buffer。
>
> 在MySQL当中，我们可以通过参数join_buffer_size来设置join buffer的值，然后再进行操作。默认情况下join_buffer_size=256K，在查找的时候MySQL会将所有的需要的列缓存到join buffer当中，包括select的列，而不是仅仅只缓存关联列。

+ 说说awk 命令

> ## 1、awk 的基本用法
>
> awk 是以文件的一行为处理单位的，awk每接收文件的一行，就执行相应的命令。
>
> **1、基本命令格式：**
>
> ```bash
> awk '{pattern + action}' <file>
> ```
>
> 其中，pattern表示在数据中要查找的内容，action表示要执行的一系列命令。
>
> awk 通过指定分隔符，将一行分为多个字段，依次用 $1、$2 ... $n 表示第一个字段、第二个字段... 第n个字段。比如有一log文件，若只想获取 vel、acc、steer 的值，则可以通过下面的命令：
>
> ```bash
> awk '{print $2, $4, $6}' log
> ```
>
> ![image-20210809234432764](https://gitee.com/ahrunio/pic-go-image-hosting-service/raw/master/img/image-20210809234432764.png)
>
> **2、awk 的分隔符**
>
> awk的默认分隔符是空格和制表符，上面的例子中，若希望把逗号去掉，则可以使用 -F 参数来指定分隔符，命令如下：
>
> ```bash
> awk -F ':|,' '{print $2, $4, $6}' log
> ```
>
> 这里指定冒号（:）和逗号（,）同时作为分隔符。
>
> ![image-20210809234518071](https://gitee.com/ahrunio/pic-go-image-hosting-service/raw/master/img/image-20210809234518071.png)
>
> **3、awk 的内置变量**
>
> 除了 $1、$2 ... $n，awk 还有一些内置变量，常用的如下：
>
> - $0：表示当前整行，$1表示第一个字段，$2表示第二个字段，$n 表示第n个字段；
> - NR：表示当前已读的行数；
> - NF：表示当前行被分割的列数，NF表示最后一个字段，NF-1 表示倒数第二个字段；
> - FILENAME：表示当前文件的名称
>
> 如下图所示，在每一行前加上文件名、行号、每行列数，命令如下：
>
> ```bash
> awk '{print FILENAME, NR, NF, ":", $0}' log
> ```
>
> ![image-20210809234625631](https://gitee.com/ahrunio/pic-go-image-hosting-service/raw/master/img/image-20210809234625631.png)
>
> **4、条件判断**
>
> awk 的 pattern 也支持使用条件判断，比如只打印 vel 小于 5.0 的行，命令如下：
>
> ```bash
> awk '$2 < 5.0 {print $0}' log
> ```
>
> ![image-20210809234711426](https://gitee.com/ahrunio/pic-go-image-hosting-service/raw/master/img/image-20210809234711426.png)

+ 同一进程中的线程可以共享哪些数据？

>
> 进程代码段
>
> 进程的公有数据（全局变量、静态变量...）
>
> 进程打开的文件描述符
>
> 文件描述符是一个简单的整数，用以 标明每一个被进程所打开的文件和socket。第一个打开的文件是0，第二个是1，依此类推。
>
> 进程的当前目录
>
> 信号处理器/信号处理函数：对收到的信号的处理方式
>
> 进程ID与进程组ID

+ 线程独占哪些资源？

> 线程ID
>
> 一组寄存器的值
>
> 线程的栈（堆是共享的）
>
> 错误返回码：线程可能会产生不同的错误返回码，一个线程的错误返回码不应该被其它线程修改；
>
> 信号掩码/信号屏蔽字(Signal mask)：表示是否屏蔽/阻塞相应的信号（SIGKILL,SIGSTOP除外）

+ 什么是协程？

> 协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。
>
> 协程多与线程进行比较：
> 一个线程可以拥有多个协程，一个进程也可以单独拥有多个协程
> 线程进程都是同步机制，而协程则是异步
> 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态

+ 进程的内存分布

>  自底向上的方式进行讲解：
>
>   1. 代码段：主要是程序的代码以及编译时静态链接进来的库。这段内存大小在程序运行之前就已经确定，而且是只读，可能存在一些常量，比如字符串常量。
>
>   2. 数据段：分为data和bss两个段，表现为静态内存段，data段存放已初始化的全局变量（静态内存分配的变量和初始化全局变量）。bss段存放未初始化的全局变量，在内存中bss段被清零。
>
>   3. 堆  段：用于程序动态内存分配和管理，如何分配和管理由程序的开发者决定，大小不固定（跟您的机器内存有关系），可以动态伸缩。
>
>   4. 映射段：该内存区域存放链接其它动态程序库的向量，共享内存映射向量等等。
>
>   5. 栈  段：栈是一种先进后出的数据结构，该段内存区域由程序在运行中自行管理，如：局部变量保存和撤除、函数调用相关等。
>
>   6. 输入的环境变量和参数段：主要内存程序执行时的环境变量，输入参数等等。
>
>   7. 就是系统区域。
>
>      ![image-20210809234932908](https://gitee.com/ahrunio/pic-go-image-hosting-service/raw/master/img/image-20210809234932908.png)